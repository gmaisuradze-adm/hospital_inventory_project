{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bde06561",
   "metadata": {},
   "source": [
    "# AI Module: Demand Forecasting and Inventory Optimization Analysis\n",
    "\n",
    "## Hospital IT Inventory Management System\n",
    "\n",
    "This comprehensive notebook implements an AI-powered solution for predicting IT asset demand and optimizing inventory levels to reduce costs and prevent stockouts in the hospital environment.\n",
    "\n",
    "### Table of Contents\n",
    "1. [Project Structure Setup](#project-structure)\n",
    "2. [Environment and Dependency Installation](#environment-setup)\n",
    "3. [Data Loading Utilities Implementation](#data-loading)\n",
    "4. [Data Preprocessing Module Implementation](#data-preprocessing)\n",
    "5. [Demand Forecasting Model Implementation](#demand-forecasting)\n",
    "6. [Inventory Optimization Algorithm Implementation](#inventory-optimization)\n",
    "7. [Model Training and Evaluation](#model-evaluation)\n",
    "8. [Results Visualization](#visualization)\n",
    "9. [Integration with Hospital System](#integration)\n",
    "\n",
    "### Project Overview\n",
    "- **Objective**: Build AI models to forecast demand and optimize inventory\n",
    "- **Data Sources**: Hospital inventory database, IT requests, procurement history\n",
    "- **Models**: Time series forecasting (ARIMA, Prophet, LSTM) and optimization algorithms\n",
    "- **Output**: Automated inventory recommendations and demand predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f323e45",
   "metadata": {},
   "source": [
    "## 1. Project Structure Setup {#project-structure}\n",
    "\n",
    "Let's create the recommended directory and file structure for our AI inventory optimization project. This structure ensures proper organization and modularity of our codebase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68403759",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "import logging\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Define the project root directory\n",
    "PROJECT_ROOT = Path(\"/workspaces/hospital_inventory_project/ai-module\")\n",
    "\n",
    "# Define the project structure\n",
    "project_structure = {\n",
    "    \"src\": {\n",
    "        \"data\": [\"__init__.py\", \"data_loader.py\", \"data_preprocessor.py\"],\n",
    "        \"models\": [\"__init__.py\", \"demand_forecaster.py\", \"inventory_optimizer.py\"],\n",
    "        \"utils\": [\"__init__.py\", \"config.py\", \"evaluation.py\"],\n",
    "        \"visualization\": [\"__init__.py\", \"visualization.py\"],\n",
    "        \"api\": [\"__init__.py\", \"app.py\", \"endpoints.py\"]\n",
    "    },\n",
    "    \"tests\": [\"__init__.py\", \"test_data.py\", \"test_models.py\", \"test_utils.py\"],\n",
    "    \"notebooks\": [\"exploratory_analysis.ipynb\", \"model_development.ipynb\", \"model_evaluation.ipynb\"],\n",
    "    \"data\": {\n",
    "        \"raw\": [],\n",
    "        \"processed\": [],\n",
    "        \"sample\": []\n",
    "    },\n",
    "    \"models\": [\"trained\", \"checkpoints\"],\n",
    "    \"docs\": [],\n",
    "    \"config\": []\n",
    "}\n",
    "\n",
    "def create_project_structure(base_path: Path, structure: dict):\n",
    "    \"\"\"\n",
    "    Create the project directory structure.\n",
    "    \n",
    "    Args:\n",
    "        base_path: Base directory path\n",
    "        structure: Nested dictionary representing the structure\n",
    "    \"\"\"\n",
    "    for name, content in structure.items():\n",
    "        current_path = base_path / name\n",
    "        \n",
    "        if isinstance(content, dict):\n",
    "            # Create directory and recurse\n",
    "            current_path.mkdir(parents=True, exist_ok=True)\n",
    "            logger.info(f\"Created directory: {current_path}\")\n",
    "            create_project_structure(current_path, content)\n",
    "        elif isinstance(content, list):\n",
    "            # Create directory and files\n",
    "            current_path.mkdir(parents=True, exist_ok=True)\n",
    "            logger.info(f\"Created directory: {current_path}\")\n",
    "            \n",
    "            for file_name in content:\n",
    "                file_path = current_path / file_name\n",
    "                if not file_path.exists():\n",
    "                    file_path.touch()\n",
    "                    logger.info(f\"Created file: {file_path}\")\n",
    "\n",
    "# Create the project structure\n",
    "print(\"Creating AI Module project structure...\")\n",
    "create_project_structure(PROJECT_ROOT, project_structure)\n",
    "\n",
    "# Add the src directory to Python path for imports\n",
    "src_path = str(PROJECT_ROOT / \"src\")\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)\n",
    "\n",
    "print(f\"\\nProject structure created at: {PROJECT_ROOT}\")\n",
    "print(\"\\nDirectory tree:\")\n",
    "for root, dirs, files in os.walk(PROJECT_ROOT):\n",
    "    level = root.replace(str(PROJECT_ROOT), '').count(os.sep)\n",
    "    indent = ' ' * 2 * level\n",
    "    print(f\"{indent}{os.path.basename(root)}/\")\n",
    "    subindent = ' ' * 2 * (level + 1)\n",
    "    for file in files:\n",
    "        print(f\"{subindent}{file}\")\n",
    "        if len(files) > 5:  # Limit output for readability\n",
    "            remaining = len(files) - 5\n",
    "            print(f\"{subindent}... and {remaining} more files\")\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f2f8e5",
   "metadata": {},
   "source": [
    "## 2. Environment and Dependency Installation {#environment-setup}\n",
    "\n",
    "Setting up the Python environment and installing required dependencies for our AI inventory optimization system. This includes data science libraries, machine learning frameworks, and database connectivity tools."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72339ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import importlib\n",
    "from pathlib import Path\n",
    "\n",
    "# Core dependencies for AI inventory optimization\n",
    "REQUIRED_PACKAGES = [\n",
    "    \"pandas>=1.5.0\",\n",
    "    \"numpy>=1.20.0\", \n",
    "    \"scikit-learn>=1.1.0\",\n",
    "    \"scipy>=1.9.0\",\n",
    "    \"matplotlib>=3.5.0\",\n",
    "    \"seaborn>=0.11.0\",\n",
    "    \"plotly>=5.10.0\",\n",
    "    \"psycopg2-binary>=2.9.0\",\n",
    "    \"sqlalchemy>=1.4.0\",\n",
    "    \"python-dotenv>=0.19.0\"\n",
    "]\n",
    "\n",
    "# Optional advanced packages (install if available)\n",
    "OPTIONAL_PACKAGES = [\n",
    "    \"prophet>=1.1.0\",\n",
    "    \"statsmodels>=0.13.0\", \n",
    "    \"tensorflow>=2.10.0\",\n",
    "    \"torch>=1.12.0\",\n",
    "    \"cvxpy>=1.2.0\",\n",
    "    \"pulp>=2.6.0\"\n",
    "]\n",
    "\n",
    "def install_package(package):\n",
    "    \"\"\"Install a package using pip.\"\"\"\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "        return True\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Failed to install {package}: {e}\")\n",
    "        return False\n",
    "\n",
    "def check_package_installed(package_name):\n",
    "    \"\"\"Check if a package is already installed.\"\"\"\n",
    "    try:\n",
    "        importlib.import_module(package_name.split('>=')[0].split('==')[0])\n",
    "        return True\n",
    "    except ImportError:\n",
    "        return False\n",
    "\n",
    "# Install core dependencies\n",
    "print(\"Installing core dependencies...\")\n",
    "for package in REQUIRED_PACKAGES:\n",
    "    package_name = package.split('>=')[0].split('==')[0]\n",
    "    if not check_package_installed(package_name):\n",
    "        print(f\"Installing {package}...\")\n",
    "        install_package(package)\n",
    "    else:\n",
    "        print(f\"✓ {package_name} already installed\")\n",
    "\n",
    "# Install optional dependencies\n",
    "print(\"\\nInstalling optional advanced packages...\")\n",
    "for package in OPTIONAL_PACKAGES:\n",
    "    package_name = package.split('>=')[0].split('==')[0]\n",
    "    if not check_package_installed(package_name):\n",
    "        print(f\"Attempting to install {package}...\")\n",
    "        if install_package(package):\n",
    "            print(f\"✓ Successfully installed {package_name}\")\n",
    "        else:\n",
    "            print(f\"⚠ Failed to install {package_name} (optional)\")\n",
    "    else:\n",
    "        print(f\"✓ {package_name} already installed\")\n",
    "\n",
    "# Verify essential imports\n",
    "print(\"\\nVerifying essential imports...\")\n",
    "try:\n",
    "    import pandas as pd\n",
    "    import numpy as np\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    import sklearn\n",
    "    import sqlalchemy\n",
    "    print(\"✓ All essential packages imported successfully\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Import error: {e}\")\n",
    "\n",
    "# Display installed versions\n",
    "print(\"\\nInstalled package versions:\")\n",
    "essential_packages = ['pandas', 'numpy', 'matplotlib', 'seaborn', 'sklearn', 'sqlalchemy']\n",
    "for pkg in essential_packages:\n",
    "    try:\n",
    "        module = importlib.import_module(pkg)\n",
    "        version = getattr(module, '__version__', 'unknown')\n",
    "        print(f\"  {pkg}: {version}\")\n",
    "    except ImportError:\n",
    "        print(f\"  {pkg}: not installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0c91fd5",
   "metadata": {},
   "source": [
    "## 3. Data Loading Utilities Implementation {#data-loading}\n",
    "\n",
    "Implementing comprehensive data loading utilities to connect to the hospital inventory PostgreSQL database and extract relevant data for AI analysis. This includes inventory history, IT requests, procurement data, and audit logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a07990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries for data loading\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sqlalchemy import create_engine, text\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "class HospitalDataLoader:\n",
    "    \"\"\"\n",
    "    Advanced data loader for hospital inventory system with comprehensive querying capabilities.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_url=None):\n",
    "        \"\"\"Initialize with database connection.\"\"\"\n",
    "        self.db_url = db_url or os.getenv(\n",
    "            'DATABASE_URL', \n",
    "            'postgresql://postgres:postgres@localhost:5432/hospital_inventory'\n",
    "        )\n",
    "        self.engine = create_engine(self.db_url)\n",
    "        print(f\"Connected to database: {self.db_url.split('@')[-1]}\")\n",
    "    \n",
    "    def load_inventory_history(self, days_back=365, item_categories=None):\n",
    "        \"\"\"\n",
    "        Load comprehensive inventory history with temporal analysis.\n",
    "        \n",
    "        Args:\n",
    "            days_back: Number of days to look back\n",
    "            item_categories: List of categories to filter\n",
    "        \"\"\"\n",
    "        start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            i.id as item_id,\n",
    "            i.name,\n",
    "            i.category,\n",
    "            i.quantity,\n",
    "            i.min_quantity,\n",
    "            i.location,\n",
    "            i.status,\n",
    "            i.unit_price,\n",
    "            i.purchase_date,\n",
    "            i.warranty_expiry,\n",
    "            i.created_at,\n",
    "            i.updated_at,\n",
    "            -- Calculate days since last update\n",
    "            EXTRACT(DAYS FROM (NOW() - i.updated_at)) as days_since_update,\n",
    "            -- Calculate stock ratio\n",
    "            CASE \n",
    "                WHEN i.min_quantity > 0 THEN i.quantity::float / i.min_quantity\n",
    "                ELSE NULL \n",
    "            END as stock_ratio\n",
    "        FROM inventory_items i\n",
    "        WHERE i.updated_at >= :start_date\n",
    "        \"\"\"\n",
    "        \n",
    "        params = {'start_date': start_date}\n",
    "        \n",
    "        if item_categories:\n",
    "            query += \" AND i.category = ANY(:categories)\"\n",
    "            params['categories'] = item_categories\n",
    "        \n",
    "        query += \" ORDER BY i.updated_at DESC\"\n",
    "        \n",
    "        df = pd.read_sql(text(query), self.engine, params=params)\n",
    "        df['updated_at'] = pd.to_datetime(df['updated_at'])\n",
    "        df['purchase_date'] = pd.to_datetime(df['purchase_date'], errors='coerce')\n",
    "        df['warranty_expiry'] = pd.to_datetime(df['warranty_expiry'], errors='coerce')\n",
    "        \n",
    "        print(f\"Loaded {len(df)} inventory records from {len(df['item_id'].unique())} unique items\")\n",
    "        return df\n",
    "    \n",
    "    def load_demand_patterns(self, days_back=365):\n",
    "        \"\"\"Load IT request patterns to understand demand.\"\"\"\n",
    "        start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            r.id as request_id,\n",
    "            r.title,\n",
    "            r.description,\n",
    "            r.request_type,\n",
    "            r.priority,\n",
    "            r.status,\n",
    "            r.created_at,\n",
    "            r.updated_at,\n",
    "            u.department,\n",
    "            u.role as user_role,\n",
    "            -- Extract month and day patterns\n",
    "            EXTRACT(MONTH FROM r.created_at) as request_month,\n",
    "            EXTRACT(DOW FROM r.created_at) as request_dow,\n",
    "            EXTRACT(HOUR FROM r.created_at) as request_hour,\n",
    "            -- Calculate resolution time\n",
    "            CASE \n",
    "                WHEN r.updated_at > r.created_at \n",
    "                THEN EXTRACT(DAYS FROM (r.updated_at - r.created_at))\n",
    "                ELSE NULL \n",
    "            END as resolution_days\n",
    "        FROM it_requests r\n",
    "        JOIN users u ON r.requested_by = u.id\n",
    "        WHERE r.created_at >= :start_date\n",
    "        ORDER BY r.created_at DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(text(query), self.engine, params={'start_date': start_date})\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        df['updated_at'] = pd.to_datetime(df['updated_at'])\n",
    "        \n",
    "        print(f\"Loaded {len(df)} IT request records\")\n",
    "        return df\n",
    "    \n",
    "    def load_procurement_analytics(self, days_back=365):\n",
    "        \"\"\"Load procurement data for supply chain analysis.\"\"\"\n",
    "        start_date = (datetime.now() - timedelta(days=days_back)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            p.id as procurement_id,\n",
    "            p.item_name,\n",
    "            p.description,\n",
    "            p.quantity,\n",
    "            p.unit_price,\n",
    "            p.total_cost,\n",
    "            p.urgency,\n",
    "            p.status,\n",
    "            p.created_at,\n",
    "            p.updated_at,\n",
    "            u.department as requester_department,\n",
    "            u.role as requester_role,\n",
    "            -- Calculate procurement velocity\n",
    "            EXTRACT(DAYS FROM (p.updated_at - p.created_at)) as procurement_days,\n",
    "            -- Seasonal patterns\n",
    "            EXTRACT(QUARTER FROM p.created_at) as procurement_quarter,\n",
    "            EXTRACT(MONTH FROM p.created_at) as procurement_month\n",
    "        FROM procurement_requests p\n",
    "        JOIN users u ON p.requested_by = u.id\n",
    "        WHERE p.created_at >= :start_date\n",
    "        ORDER BY p.created_at DESC\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(text(query), self.engine, params={'start_date': start_date})\n",
    "        df['created_at'] = pd.to_datetime(df['created_at'])\n",
    "        df['updated_at'] = pd.to_datetime(df['updated_at'])\n",
    "        \n",
    "        print(f\"Loaded {len(df)} procurement records\")\n",
    "        return df\n",
    "    \n",
    "    def load_current_inventory_snapshot(self):\n",
    "        \"\"\"Get current state for optimization.\"\"\"\n",
    "        query = \"\"\"\n",
    "        SELECT \n",
    "            i.*,\n",
    "            -- Calculate inventory metrics\n",
    "            CASE \n",
    "                WHEN i.min_quantity > 0 THEN i.quantity::float / i.min_quantity\n",
    "                ELSE NULL \n",
    "            END as stock_ratio,\n",
    "            CASE \n",
    "                WHEN i.quantity <= i.min_quantity THEN true\n",
    "                ELSE false \n",
    "            END as is_low_stock,\n",
    "            -- Days since last purchase\n",
    "            CASE \n",
    "                WHEN i.purchase_date IS NOT NULL \n",
    "                THEN EXTRACT(DAYS FROM (NOW() - i.purchase_date))\n",
    "                ELSE NULL \n",
    "            END as days_since_purchase,\n",
    "            -- Warranty status\n",
    "            CASE \n",
    "                WHEN i.warranty_expiry IS NOT NULL \n",
    "                THEN EXTRACT(DAYS FROM (i.warranty_expiry - NOW()))\n",
    "                ELSE NULL \n",
    "            END as warranty_days_remaining\n",
    "        FROM inventory_items i\n",
    "        WHERE i.status != 'RETIRED'\n",
    "        ORDER BY i.category, i.name\n",
    "        \"\"\"\n",
    "        \n",
    "        df = pd.read_sql(text(query), self.engine)\n",
    "        print(f\"Current inventory snapshot: {len(df)} active items\")\n",
    "        return df\n",
    "\n",
    "# Initialize data loader\n",
    "print(\"Initializing Hospital Data Loader...\")\n",
    "data_loader = HospitalDataLoader()\n",
    "\n",
    "# Load sample data for analysis\n",
    "print(\"\\nLoading sample data for AI analysis...\")\n",
    "\n",
    "# Load inventory history (last 6 months)\n",
    "inventory_data = data_loader.load_inventory_history(days_back=180)\n",
    "\n",
    "# Load demand patterns\n",
    "demand_data = data_loader.load_demand_patterns(days_back=180)\n",
    "\n",
    "# Load procurement data  \n",
    "procurement_data = data_loader.load_procurement_analytics(days_back=180)\n",
    "\n",
    "# Get current inventory snapshot\n",
    "current_inventory = data_loader.load_current_inventory_snapshot()\n",
    "\n",
    "# Display basic statistics\n",
    "print(f\"\\n=== DATA LOADING SUMMARY ===\")\n",
    "print(f\"Inventory History: {len(inventory_data)} records\")\n",
    "print(f\"Demand Patterns: {len(demand_data)} requests\") \n",
    "print(f\"Procurement Data: {len(procurement_data)} transactions\")\n",
    "print(f\"Current Inventory: {len(current_inventory)} items\")\n",
    "\n",
    "# Quick data quality check\n",
    "print(f\"\\n=== DATA QUALITY CHECK ===\")\n",
    "print(f\"Inventory null values: {inventory_data.isnull().sum().sum()}\")\n",
    "print(f\"Demand null values: {demand_data.isnull().sum().sum()}\")\n",
    "print(f\"Procurement null values: {procurement_data.isnull().sum().sum()}\")\n",
    "print(f\"Current inventory null values: {current_inventory.isnull().sum().sum()}\")\n",
    "\n",
    "# Show sample data structure\n",
    "print(f\"\\n=== SAMPLE DATA STRUCTURE ===\")\n",
    "print(\"Inventory columns:\", list(inventory_data.columns))\n",
    "print(\"Demand columns:\", list(demand_data.columns))\n",
    "print(\"Procurement columns:\", list(procurement_data.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bf3913",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing Module Implementation {#data-preprocessing}\n",
    "\n",
    "Implementing comprehensive data preprocessing pipeline to clean, transform, and prepare the hospital inventory data for machine learning models. This includes feature engineering, time series preparation, and data quality enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c4c0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, MinMaxScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "class HospitalDataPreprocessor:\n",
    "    \"\"\"\n",
    "    Advanced data preprocessing for hospital inventory AI models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.scalers = {}\n",
    "        self.encoders = {}\n",
    "        self.imputers = {}\n",
    "        print(\"Hospital Data Preprocessor initialized\")\n",
    "    \n",
    "    def create_time_series_features(self, df, timestamp_col='updated_at', target_col='quantity'):\n",
    "        \"\"\"Create comprehensive time series features.\"\"\"\n",
    "        df_processed = df.copy()\n",
    "        df_processed[timestamp_col] = pd.to_datetime(df_processed[timestamp_col])\n",
    "        \n",
    "        # Temporal features\n",
    "        df_processed['year'] = df_processed[timestamp_col].dt.year\n",
    "        df_processed['month'] = df_processed[timestamp_col].dt.month\n",
    "        df_processed['day'] = df_processed[timestamp_col].dt.day\n",
    "        df_processed['dayofweek'] = df_processed[timestamp_col].dt.dayofweek\n",
    "        df_processed['quarter'] = df_processed[timestamp_col].dt.quarter\n",
    "        df_processed['week'] = df_processed[timestamp_col].dt.isocalendar().week\n",
    "        \n",
    "        # Cyclical encoding for seasonality\n",
    "        df_processed['month_sin'] = np.sin(2 * np.pi * df_processed['month'] / 12)\n",
    "        df_processed['month_cos'] = np.cos(2 * np.pi * df_processed['month'] / 12)\n",
    "        df_processed['dayofweek_sin'] = np.sin(2 * np.pi * df_processed['dayofweek'] / 7)\n",
    "        df_processed['dayofweek_cos'] = np.cos(2 * np.pi * df_processed['dayofweek'] / 7)\n",
    "        \n",
    "        # Business calendar features\n",
    "        df_processed['is_weekend'] = df_processed['dayofweek'].isin([5, 6]).astype(int)\n",
    "        df_processed['is_month_start'] = df_processed[timestamp_col].dt.is_month_start.astype(int)\n",
    "        df_processed['is_month_end'] = df_processed[timestamp_col].dt.is_month_end.astype(int)\n",
    "        df_processed['is_quarter_start'] = df_processed[timestamp_col].dt.is_quarter_start.astype(int)\n",
    "        df_processed['is_quarter_end'] = df_processed[timestamp_col].dt.is_quarter_end.astype(int)\n",
    "        \n",
    "        print(f\"Created time series features, shape: {df_processed.shape}\")\n",
    "        return df_processed\n",
    "    \n",
    "    def create_inventory_features(self, df):\n",
    "        \"\"\"Create inventory-specific features.\"\"\"\n",
    "        df_features = df.copy()\n",
    "        \n",
    "        # Stock level indicators\n",
    "        df_features['stock_status'] = pd.cut(\n",
    "            df_features['stock_ratio'].fillna(1), \n",
    "            bins=[0, 0.5, 1.0, 2.0, float('inf')], \n",
    "            labels=['Critical', 'Low', 'Normal', 'High']\n",
    "        )\n",
    "        \n",
    "        # Age-based features\n",
    "        if 'days_since_purchase' in df_features.columns:\n",
    "            df_features['asset_age_category'] = pd.cut(\n",
    "                df_features['days_since_purchase'].fillna(0),\n",
    "                bins=[0, 365, 1095, 1825, float('inf')],\n",
    "                labels=['New', 'Young', 'Mature', 'Old']\n",
    "            )\n",
    "        \n",
    "        # Value-based features\n",
    "        if 'unit_price' in df_features.columns:\n",
    "            df_features['value_category'] = pd.qcut(\n",
    "                df_features['unit_price'].fillna(df_features['unit_price'].median()),\n",
    "                q=4, labels=['Low', 'Medium', 'High', 'Premium']\n",
    "            )\n",
    "        \n",
    "        # Location-based grouping\n",
    "        if 'location' in df_features.columns:\n",
    "            location_counts = df_features['location'].value_counts()\n",
    "            df_features['location_frequency'] = df_features['location'].map(location_counts)\n",
    "        \n",
    "        print(f\"Created inventory features, shape: {df_features.shape}\")\n",
    "        return df_features\n",
    "    \n",
    "    def create_demand_aggregations(self, demand_df, inventory_df):\n",
    "        \"\"\"Create demand aggregation features.\"\"\"\n",
    "        # Aggregate demand by category and time period\n",
    "        demand_df['date'] = demand_df['created_at'].dt.date\n",
    "        \n",
    "        # Daily demand counts by request type\n",
    "        daily_demand = demand_df.groupby(['date', 'request_type']).size().reset_index(name='daily_requests')\n",
    "        \n",
    "        # Weekly demand trends\n",
    "        demand_df['week'] = demand_df['created_at'].dt.isocalendar().week\n",
    "        weekly_demand = demand_df.groupby(['week', 'request_type']).agg({\n",
    "            'request_id': 'count',\n",
    "            'priority': lambda x: (x == 'HIGH').sum() + (x == 'CRITICAL').sum() * 2\n",
    "        }).reset_index()\n",
    "        weekly_demand.columns = ['week', 'request_type', 'weekly_requests', 'urgency_score']\n",
    "        \n",
    "        # Department-based demand patterns\n",
    "        dept_demand = demand_df.groupby(['department', 'request_type']).agg({\n",
    "            'request_id': 'count',\n",
    "            'resolution_days': 'mean'\n",
    "        }).reset_index()\n",
    "        dept_demand.columns = ['department', 'request_type', 'dept_request_count', 'avg_resolution_days']\n",
    "        \n",
    "        print(f\"Created demand aggregations\")\n",
    "        return {\n",
    "            'daily': daily_demand,\n",
    "            'weekly': weekly_demand, \n",
    "            'department': dept_demand\n",
    "        }\n",
    "    \n",
    "    def create_lag_features(self, df, value_cols, group_col='item_id', lags=[1, 3, 7, 14, 30]):\n",
    "        \"\"\"Create lagged features for time series modeling.\"\"\"\n",
    "        df_lagged = df.copy()\n",
    "        df_lagged = df_lagged.sort_values([group_col, 'updated_at'])\n",
    "        \n",
    "        for col in value_cols:\n",
    "            if col in df_lagged.columns:\n",
    "                for lag in lags:\n",
    "                    df_lagged[f'{col}_lag_{lag}'] = (\n",
    "                        df_lagged.groupby(group_col)[col].shift(lag)\n",
    "                    )\n",
    "                \n",
    "                # Rolling statistics\n",
    "                for window in [7, 14, 30]:\n",
    "                    df_lagged[f'{col}_rolling_mean_{window}'] = (\n",
    "                        df_lagged.groupby(group_col)[col]\n",
    "                        .rolling(window=window, min_periods=1)\n",
    "                        .mean()\n",
    "                        .reset_index(level=0, drop=True)\n",
    "                    )\n",
    "                    \n",
    "                    df_lagged[f'{col}_rolling_std_{window}'] = (\n",
    "                        df_lagged.groupby(group_col)[col]\n",
    "                        .rolling(window=window, min_periods=1)\n",
    "                        .std()\n",
    "                        .reset_index(level=0, drop=True)\n",
    "                    )\n",
    "        \n",
    "        print(f\"Created lag features for {value_cols}\")\n",
    "        return df_lagged\n",
    "    \n",
    "    def encode_categorical_features(self, df, categorical_cols):\n",
    "        \"\"\"Encode categorical features using appropriate methods.\"\"\"\n",
    "        df_encoded = df.copy()\n",
    "        \n",
    "        for col in categorical_cols:\n",
    "            if col in df_encoded.columns:\n",
    "                # Handle special ordinal categories\n",
    "                if col in ['priority', 'urgency']:\n",
    "                    priority_map = {'LOW': 1, 'MEDIUM': 2, 'HIGH': 3, 'CRITICAL': 4}\n",
    "                    df_encoded[f'{col}_encoded'] = df_encoded[col].map(priority_map).fillna(1)\n",
    "                \n",
    "                elif col in ['status']:\n",
    "                    status_map = {\n",
    "                        'AVAILABLE': 1, 'IN_USE': 2, 'MAINTENANCE': 3, \n",
    "                        'DAMAGED': 4, 'RETIRED': 5, 'RESERVED': 6\n",
    "                    }\n",
    "                    df_encoded[f'{col}_encoded'] = df_encoded[col].map(status_map).fillna(1)\n",
    "                \n",
    "                else:\n",
    "                    # Standard label encoding\n",
    "                    if col not in self.encoders:\n",
    "                        self.encoders[col] = LabelEncoder()\n",
    "                        df_encoded[f'{col}_encoded'] = self.encoders[col].fit_transform(\n",
    "                            df_encoded[col].fillna('Unknown')\n",
    "                        )\n",
    "                    else:\n",
    "                        # Handle unseen categories\n",
    "                        known_categories = set(self.encoders[col].classes_)\n",
    "                        df_encoded[col] = df_encoded[col].fillna('Unknown')\n",
    "                        \n",
    "                        # Map unseen categories to 'Unknown'\n",
    "                        df_encoded[col] = df_encoded[col].apply(\n",
    "                            lambda x: x if x in known_categories else 'Unknown'\n",
    "                        )\n",
    "                        \n",
    "                        df_encoded[f'{col}_encoded'] = self.encoders[col].transform(df_encoded[col])\n",
    "        \n",
    "        print(f\"Encoded categorical features: {categorical_cols}\")\n",
    "        return df_encoded\n",
    "    \n",
    "    def handle_missing_values(self, df, strategy=None):\n",
    "        \"\"\"Handle missing values with appropriate strategies.\"\"\"\n",
    "        if strategy is None:\n",
    "            strategy = {'numeric': 'median', 'categorical': 'most_frequent'}\n",
    "        \n",
    "        df_imputed = df.copy()\n",
    "        \n",
    "        # Separate numeric and categorical columns\n",
    "        numeric_cols = df_imputed.select_dtypes(include=[np.number]).columns\n",
    "        categorical_cols = df_imputed.select_dtypes(include=['object', 'category']).columns\n",
    "        \n",
    "        # Impute numeric columns\n",
    "        if len(numeric_cols) > 0:\n",
    "            if 'numeric' not in self.imputers:\n",
    "                self.imputers['numeric'] = SimpleImputer(strategy=strategy['numeric'])\n",
    "                df_imputed[numeric_cols] = self.imputers['numeric'].fit_transform(df_imputed[numeric_cols])\n",
    "            else:\n",
    "                df_imputed[numeric_cols] = self.imputers['numeric'].transform(df_imputed[numeric_cols])\n",
    "        \n",
    "        # Impute categorical columns\n",
    "        if len(categorical_cols) > 0:\n",
    "            if 'categorical' not in self.imputers:\n",
    "                self.imputers['categorical'] = SimpleImputer(strategy=strategy['categorical'])\n",
    "                df_imputed[categorical_cols] = self.imputers['categorical'].fit_transform(df_imputed[categorical_cols])\n",
    "            else:\n",
    "                df_imputed[categorical_cols] = self.imputers['categorical'].transform(df_imputed[categorical_cols])\n",
    "        \n",
    "        print(f\"Handled missing values using strategies: {strategy}\")\n",
    "        return df_imputed\n",
    "\n",
    "# Initialize preprocessor\n",
    "preprocessor = HospitalDataPreprocessor()\n",
    "\n",
    "# Process inventory data\n",
    "print(\"Processing inventory data...\")\n",
    "inventory_processed = preprocessor.create_time_series_features(inventory_data)\n",
    "inventory_processed = preprocessor.create_inventory_features(inventory_processed)\n",
    "\n",
    "# Create lag features for quantity tracking\n",
    "inventory_with_lags = preprocessor.create_lag_features(\n",
    "    inventory_processed, \n",
    "    ['quantity', 'stock_ratio'], \n",
    "    group_col='item_id'\n",
    ")\n",
    "\n",
    "# Process demand data\n",
    "print(\"\\nProcessing demand data...\")\n",
    "demand_processed = preprocessor.create_time_series_features(\n",
    "    demand_data, \n",
    "    timestamp_col='created_at', \n",
    "    target_col='request_id'\n",
    ")\n",
    "\n",
    "# Create demand aggregations\n",
    "demand_aggregations = preprocessor.create_demand_aggregations(demand_processed, inventory_processed)\n",
    "\n",
    "# Encode categorical features\n",
    "categorical_cols = ['category', 'location', 'status', 'request_type', 'priority', 'department']\n",
    "inventory_encoded = preprocessor.encode_categorical_features(inventory_with_lags, categorical_cols)\n",
    "demand_encoded = preprocessor.encode_categorical_features(demand_processed, categorical_cols)\n",
    "\n",
    "# Handle missing values\n",
    "inventory_final = preprocessor.handle_missing_values(inventory_encoded)\n",
    "demand_final = preprocessor.handle_missing_values(demand_encoded)\n",
    "\n",
    "print(f\"\\n=== PREPROCESSING SUMMARY ===\")\n",
    "print(f\"Original inventory shape: {inventory_data.shape}\")\n",
    "print(f\"Processed inventory shape: {inventory_final.shape}\")\n",
    "print(f\"Original demand shape: {demand_data.shape}\")\n",
    "print(f\"Processed demand shape: {demand_final.shape}\")\n",
    "print(f\"Created features: {inventory_final.shape[1] - inventory_data.shape[1]} new inventory features\")\n",
    "print(f\"Created features: {demand_final.shape[1] - demand_data.shape[1]} new demand features\")\n",
    "\n",
    "# Show feature categories\n",
    "feature_categories = {\n",
    "    'temporal': [col for col in inventory_final.columns if any(x in col for x in ['month', 'day', 'week', 'quarter', 'sin', 'cos'])],\n",
    "    'lag': [col for col in inventory_final.columns if 'lag' in col or 'rolling' in col],\n",
    "    'categorical': [col for col in inventory_final.columns if 'encoded' in col],\n",
    "    'derived': [col for col in inventory_final.columns if any(x in col for x in ['ratio', 'status', 'category', 'age'])]\n",
    "}\n",
    "\n",
    "print(f\"\\n=== FEATURE CATEGORIES ===\")\n",
    "for category, features in feature_categories.items():\n",
    "    print(f\"{category.capitalize()}: {len(features)} features\")\n",
    "    if len(features) <= 5:\n",
    "        print(f\"  {features}\")\n",
    "    else:\n",
    "        print(f\"  {features[:3]} ... and {len(features)-3} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8e2728",
   "metadata": {},
   "source": [
    "## 5. Demand Forecasting Model Implementation\n",
    "\n",
    "Now we'll implement and train multiple forecasting models to predict future demand for hospital IT equipment. We'll use various approaches including ARIMA, Prophet, LSTM, and machine learning models to ensure robust predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf27fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test the demand forecasting models\n",
    "from src.models.demand_forecaster import DemandForecaster\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Create sample demand data for demonstration\n",
    "np.random.seed(42)\n",
    "dates = pd.date_range('2023-01-01', periods=365, freq='D')\n",
    "\n",
    "# Generate realistic hospital IT demand data with trend and seasonality\n",
    "trend = np.linspace(10, 15, 365)\n",
    "seasonal = 3 * np.sin(2 * np.pi * np.arange(365) / 30)  # Monthly seasonality\n",
    "noise = np.random.normal(0, 2, 365)\n",
    "demand_values = np.maximum(0, trend + seasonal + noise).astype(int)\n",
    "\n",
    "sample_demand = pd.Series(demand_values, index=dates)\n",
    "\n",
    "print(\"Sample Demand Data Created:\")\n",
    "print(f\"- Date range: {sample_demand.index.min()} to {sample_demand.index.max()}\")\n",
    "print(f\"- Total demand: {sample_demand.sum()}\")\n",
    "print(f\"- Average daily demand: {sample_demand.mean():.2f}\")\n",
    "print(f\"- Standard deviation: {sample_demand.std():.2f}\")\n",
    "\n",
    "# Plot the sample data\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(sample_demand.index, sample_demand.values, label='Daily Demand', alpha=0.7)\n",
    "plt.title('Sample Hospital IT Equipment Demand Data')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Demand Quantity')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Initialize the demand forecaster\n",
    "forecaster = DemandForecaster()\n",
    "print(\"\\nDemand Forecaster initialized successfully!\")\n",
    "print(f\"Available models: {list(forecaster.models.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d154e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and evaluate different forecasting models\n",
    "from src.utils.evaluation import ForecastEvaluator\n",
    "\n",
    "# Split data into train and test sets\n",
    "train_size = int(len(sample_demand) * 0.8)\n",
    "train_data = sample_demand[:train_size]\n",
    "test_data = sample_demand[train_size:]\n",
    "\n",
    "print(f\"Training data: {len(train_data)} days\")\n",
    "print(f\"Test data: {len(test_data)} days\")\n",
    "\n",
    "# Train models and make predictions\n",
    "forecast_horizon = len(test_data)\n",
    "model_predictions = {}\n",
    "model_training_results = {}\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"TRAINING AND EVALUATING FORECASTING MODELS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# 1. ARIMA Model\n",
    "print(\"\\n1. Training ARIMA Model...\")\n",
    "try:\n",
    "    arima_result = forecaster.fit_arima(train_data)\n",
    "    arima_forecast = forecaster.predict(forecast_horizon, model_type='arima')\n",
    "    model_predictions['ARIMA'] = arima_forecast\n",
    "    model_training_results['ARIMA'] = arima_result\n",
    "    print(f\"   ✓ ARIMA model trained successfully\")\n",
    "    print(f\"   ✓ Model order: {getattr(arima_result, 'order', 'Auto-selected')}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ ARIMA training failed: {str(e)}\")\n",
    "\n",
    "# 2. Prophet Model\n",
    "print(\"\\n2. Training Prophet Model...\")\n",
    "try:\n",
    "    prophet_result = forecaster.fit_prophet(train_data)\n",
    "    prophet_forecast = forecaster.predict(forecast_horizon, model_type='prophet')\n",
    "    model_predictions['Prophet'] = prophet_forecast\n",
    "    model_training_results['Prophet'] = prophet_result\n",
    "    print(f\"   ✓ Prophet model trained successfully\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Prophet training failed: {str(e)}\")\n",
    "\n",
    "# 3. LSTM Model\n",
    "print(\"\\n3. Training LSTM Model...\")\n",
    "try:\n",
    "    lstm_result = forecaster.fit_lstm(train_data, epochs=50, verbose=0)\n",
    "    lstm_forecast = forecaster.predict(forecast_horizon, model_type='lstm')\n",
    "    model_predictions['LSTM'] = lstm_forecast\n",
    "    model_training_results['LSTM'] = lstm_result\n",
    "    print(f\"   ✓ LSTM model trained successfully\")\n",
    "    print(f\"   ✓ Training loss: {getattr(lstm_result, 'history', {}).get('loss', ['N/A'])[-1] if hasattr(lstm_result, 'history') else 'N/A'}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ LSTM training failed: {str(e)}\")\n",
    "\n",
    "# 4. Random Forest Model\n",
    "print(\"\\n4. Training Random Forest Model...\")\n",
    "try:\n",
    "    rf_result = forecaster.fit_random_forest(train_data)\n",
    "    rf_forecast = forecaster.predict(forecast_horizon, model_type='random_forest')\n",
    "    model_predictions['Random Forest'] = rf_forecast\n",
    "    model_training_results['Random Forest'] = rf_result\n",
    "    print(f\"   ✓ Random Forest model trained successfully\")\n",
    "    print(f\"   ✓ Number of estimators: {getattr(rf_result, 'n_estimators', 'N/A')}\")\n",
    "except Exception as e:\n",
    "    print(f\"   ✗ Random Forest training failed: {str(e)}\")\n",
    "\n",
    "print(f\"\\n✓ Successfully trained {len(model_predictions)} models\")\n",
    "print(f\"Models available: {list(model_predictions.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcbc36e1",
   "metadata": {},
   "source": [
    "## 6. Inventory Optimization Algorithm Implementation\n",
    "\n",
    "Now we'll implement inventory optimization algorithms to determine optimal stock levels, reorder points, and safety stock for hospital IT equipment based on our demand forecasts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3035ec02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and test inventory optimization\n",
    "from src.models.inventory_optimizer import InventoryOptimizer, StochasticInventoryOptimizer\n",
    "\n",
    "# Initialize the inventory optimizer\n",
    "optimizer = InventoryOptimizer(\n",
    "    service_level_target=0.95,\n",
    "    holding_cost_rate=0.25,\n",
    "    ordering_cost=150.0\n",
    ")\n",
    "\n",
    "print(\"Inventory Optimizer initialized successfully!\")\n",
    "print(f\"Service level target: {optimizer.service_level_target}\")\n",
    "print(f\"Holding cost rate: {optimizer.holding_cost_rate}\")\n",
    "print(f\"Ordering cost: ${optimizer.ordering_cost}\")\n",
    "\n",
    "# Create sample inventory data for hospital IT equipment\n",
    "sample_items = pd.DataFrame({\n",
    "    'item_id': ['IT001', 'IT002', 'IT003', 'IT004', 'IT005'],\n",
    "    'item_name': ['Desktop Computer', 'Laptop', 'Network Switch', 'Printer', 'Server'],\n",
    "    'category': ['Hardware', 'Hardware', 'Network', 'Peripheral', 'Hardware'],\n",
    "    'unit_cost': [800, 1200, 300, 150, 5000],\n",
    "    'current_stock': [25, 15, 10, 30, 3],\n",
    "    'lead_time_days': [7, 5, 14, 3, 21],\n",
    "    'annual_demand': [100, 80, 20, 120, 5]\n",
    "})\n",
    "\n",
    "print(f\"\\nSample inventory data created:\")\n",
    "print(sample_items.to_string())\n",
    "\n",
    "# Create demand forecasts for each item (using our best model)\n",
    "item_forecasts = {}\n",
    "for item_id in sample_items['item_id']:\n",
    "    # Generate realistic demand forecast for each item\n",
    "    base_demand = sample_items[sample_items['item_id'] == item_id]['annual_demand'].iloc[0]\n",
    "    daily_demand = base_demand / 365\n",
    "    \n",
    "    # Create 30-day forecast\n",
    "    forecast_dates = pd.date_range(test_data.index[-1] + pd.Timedelta(days=1), periods=30, freq='D')\n",
    "    forecast_values = np.random.poisson(daily_demand, 30)\n",
    "    item_forecasts[item_id] = pd.Series(forecast_values, index=forecast_dates)\n",
    "\n",
    "print(f\"\\nCreated demand forecasts for {len(item_forecasts)} items\")\n",
    "print(\"Sample forecast for IT001:\")\n",
    "print(item_forecasts['IT001'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e231666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform inventory optimization for all items\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"INVENTORY OPTIMIZATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "optimization_results = []\n",
    "\n",
    "for _, item in sample_items.iterrows():\n",
    "    item_id = item['item_id']\n",
    "    item_name = item['item_name']\n",
    "    \n",
    "    print(f\"\\nOptimizing inventory for: {item_name} ({item_id})\")\n",
    "    \n",
    "    # Get demand forecast\n",
    "    forecast = item_forecasts[item_id]\n",
    "    \n",
    "    # Optimize inventory levels\n",
    "    result = optimizer.optimize_inventory_levels(\n",
    "        item.to_dict(),\n",
    "        forecast,\n",
    "        lead_time_days=item['lead_time_days']\n",
    "    )\n",
    "    \n",
    "    optimization_results.append({\n",
    "        'item_id': item_id,\n",
    "        'item_name': item_name,\n",
    "        'current_stock': item['current_stock'],\n",
    "        'optimal_order_quantity': result.optimal_order_quantity,\n",
    "        'reorder_point': result.reorder_point,\n",
    "        'safety_stock': result.safety_stock,\n",
    "        'total_cost': result.total_cost,\n",
    "        'service_level': result.service_level,\n",
    "        'abc_category': result.abc_category,\n",
    "        'unit_cost': item['unit_cost'],\n",
    "        'annual_value': item['annual_demand'] * item['unit_cost']\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✓ EOQ: {result.optimal_order_quantity:.1f} units\")\n",
    "    print(f\"  ✓ Reorder Point: {result.reorder_point:.1f} units\")\n",
    "    print(f\"  ✓ Safety Stock: {result.safety_stock:.1f} units\")\n",
    "    print(f\"  ✓ ABC Category: {result.abc_category}\")\n",
    "    print(f\"  ✓ Estimated Annual Cost: ${result.total_cost:.2f}\")\n",
    "\n",
    "# Convert to DataFrame\n",
    "optimization_df = pd.DataFrame(optimization_results)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"OPTIMIZATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(optimization_df[['item_name', 'current_stock', 'optimal_order_quantity', \n",
    "                       'reorder_point', 'abc_category']].to_string())\n",
    "\n",
    "# Perform ABC Analysis\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"ABC ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "abc_analysis = optimizer.abc_analysis(sample_items.copy(), 'annual_demand')\n",
    "print(\"\\nABC Categories Distribution:\")\n",
    "print(abc_analysis.groupby('abc_category').agg({\n",
    "    'item_name': 'count',\n",
    "    'annual_demand': 'sum',\n",
    "    'unit_cost': 'mean'\n",
    "}).round(2))\n",
    "\n",
    "# Calculate total potential savings\n",
    "current_holding_cost = (sample_items['current_stock'] * sample_items['unit_cost'] * 0.25).sum()\n",
    "optimized_holding_cost = optimization_df['total_cost'].sum()\n",
    "potential_savings = current_holding_cost - optimized_holding_cost\n",
    "savings_percentage = (potential_savings / current_holding_cost) * 100\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(\"FINANCIAL IMPACT ANALYSIS\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Current annual holding cost: ${current_holding_cost:,.2f}\")\n",
    "print(f\"Optimized annual cost: ${optimized_holding_cost:,.2f}\")\n",
    "print(f\"Potential annual savings: ${potential_savings:,.2f}\")\n",
    "print(f\"Cost reduction percentage: {savings_percentage:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0b0ac35",
   "metadata": {},
   "source": [
    "## 7. Model Training and Evaluation\n",
    "\n",
    "Let's evaluate the performance of our forecasting models and compare their accuracy using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e960fb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model performance\n",
    "evaluator = ForecastEvaluator()\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"MODEL PERFORMANCE EVALUATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Compare all models\n",
    "model_comparison = evaluator.compare_models(test_data.values, model_predictions)\n",
    "print(\"\\nModel Comparison Results:\")\n",
    "print(model_comparison.to_string(index=False))\n",
    "\n",
    "# Detailed metrics for each model\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"DETAILED METRICS BY MODEL\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for model_name, predictions in model_predictions.items():\n",
    "    print(f\"\\n{model_name} Model:\")\n",
    "    print(\"-\" * (len(model_name) + 7))\n",
    "    \n",
    "    metrics = evaluator.calculate_metrics(test_data.values, predictions)\n",
    "    \n",
    "    print(f\"  Mean Absolute Error (MAE): {metrics.mae:.3f}\")\n",
    "    print(f\"  Root Mean Square Error (RMSE): {metrics.rmse:.3f}\")\n",
    "    print(f\"  Mean Absolute Percentage Error (MAPE): {metrics.mape:.2f}%\")\n",
    "    print(f\"  Symmetric MAPE: {metrics.smape:.2f}%\")\n",
    "    print(f\"  R-squared (R²): {metrics.r2:.3f}\")\n",
    "    print(f\"  Bias: {metrics.bias:.3f}\")\n",
    "    print(f\"  Accuracy (within 10%): {metrics.accuracy:.1f}%\")\n",
    "    print(f\"  Directional Accuracy: {metrics.directional_accuracy:.1f}%\")\n",
    "\n",
    "# Identify best model\n",
    "best_model = model_comparison.iloc[0]['Model']\n",
    "best_mae = model_comparison.iloc[0]['MAE']\n",
    "\n",
    "print(f\"\\n\" + \"=\"*40)\n",
    "print(\"BEST MODEL SELECTION\")\n",
    "print(\"=\"*40)\n",
    "print(f\"Best performing model: {best_model}\")\n",
    "print(f\"Best MAE: {best_mae:.3f}\")\n",
    "print(f\"This model will be used for inventory optimization\")\n",
    "\n",
    "# Calculate confidence intervals for the best model\n",
    "if best_model in model_predictions:\n",
    "    best_predictions = model_predictions[best_model]\n",
    "    residuals = test_data.values - best_predictions\n",
    "    \n",
    "    # Calculate forecast intervals\n",
    "    lower_bound, upper_bound = evaluator.calculate_forecast_intervals(\n",
    "        best_predictions, residuals, confidence_level=0.95\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n95% Confidence Intervals:\")\n",
    "    print(f\"Average prediction: {np.mean(best_predictions):.2f}\")\n",
    "    print(f\"Average lower bound: {np.mean(lower_bound):.2f}\")\n",
    "    print(f\"Average upper bound: {np.mean(upper_bound):.2f}\")\n",
    "    print(f\"Average interval width: {np.mean(upper_bound - lower_bound):.2f}\")\n",
    "\n",
    "# Model validation using cross-validation\n",
    "from src.utils.evaluation import ModelValidator\n",
    "\n",
    "validator = ModelValidator()\n",
    "print(f\"\\n\" + \"=\"*50)\n",
    "print(\"CROSS-VALIDATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Cross-validate the best model\n",
    "best_forecaster = forecaster.models.get(best_model.lower(), forecaster.models.get('arima'))\n",
    "if best_forecaster:\n",
    "    cv_results = validator.cross_validate_forecast(\n",
    "        best_forecaster, sample_demand, n_splits=3, test_size=30\n",
    "    )\n",
    "    \n",
    "    if 'error' not in cv_results:\n",
    "        print(f\"Cross-validation results for {best_model}:\")\n",
    "        print(f\"  Mean MAE: {cv_results['mean_mae']:.3f} ± {cv_results['std_mae']:.3f}\")\n",
    "        print(f\"  Mean RMSE: {cv_results['mean_rmse']:.3f} ± {cv_results['std_rmse']:.3f}\")\n",
    "        print(f\"  Mean Accuracy: {cv_results['mean_accuracy']:.1f}% ± {cv_results['std_accuracy']:.1f}%\")\n",
    "    else:\n",
    "        print(f\"Cross-validation failed: {cv_results['error']}\")\n",
    "else:\n",
    "    print(\"Best model not available for cross-validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc81da3",
   "metadata": {},
   "source": [
    "## 8. Results Visualization\n",
    "\n",
    "Now let's create comprehensive visualizations to understand our forecasting and optimization results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243ab11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comprehensive visualizations\n",
    "from src.visualization.visualizer import InventoryVisualizer\n",
    "import plotly.io as pio\n",
    "pio.renderers.default = \"notebook\"  # For Jupyter notebook display\n",
    "\n",
    "# Initialize visualizer\n",
    "visualizer = InventoryVisualizer()\n",
    "\n",
    "print(\"Creating visualizations for demand forecasting and inventory optimization...\")\n",
    "\n",
    "# 1. Demand Forecast Visualization\n",
    "print(\"\\n1. Creating demand forecast visualization...\")\n",
    "forecast_fig = visualizer.plot_demand_forecast(\n",
    "    historical_data=train_data,\n",
    "    forecast_data=pd.Series(model_predictions[best_model], index=test_data.index),\n",
    "    title=f\"Hospital IT Equipment Demand Forecast ({best_model} Model)\"\n",
    ")\n",
    "forecast_fig.show()\n",
    "\n",
    "# 2. Model Performance Comparison\n",
    "print(\"\\n2. Creating model performance comparison...\")\n",
    "model_metrics = {}\n",
    "for model_name, predictions in model_predictions.items():\n",
    "    metrics = evaluator.calculate_metrics(test_data.values, predictions)\n",
    "    model_metrics[model_name] = {\n",
    "        'MAE': metrics.mae,\n",
    "        'RMSE': metrics.rmse,\n",
    "        'MAPE': metrics.mape,\n",
    "        'Accuracy': metrics.accuracy,\n",
    "        'R²': metrics.r2\n",
    "    }\n",
    "\n",
    "performance_fig = visualizer.plot_model_performance_comparison(\n",
    "    model_metrics,\n",
    "    title=\"Forecasting Models Performance Comparison\"\n",
    ")\n",
    "performance_fig.show()\n",
    "\n",
    "# 3. Inventory Optimization Results\n",
    "print(\"\\n3. Creating inventory optimization visualization...\")\n",
    "optimization_fig = visualizer.plot_inventory_optimization_results(\n",
    "    optimization_df,\n",
    "    title=\"Hospital IT Equipment Inventory Optimization Results\"\n",
    ")\n",
    "optimization_fig.show()\n",
    "\n",
    "# 4. ABC Analysis Visualization\n",
    "print(\"\\n4. Creating ABC analysis visualization...\")\n",
    "abc_fig = visualizer.plot_abc_analysis(\n",
    "    abc_analysis,\n",
    "    value_column='annual_demand'\n",
    ")\n",
    "abc_fig.show()\n",
    "\n",
    "# 5. Comprehensive Dashboard\n",
    "print(\"\\n5. Creating comprehensive inventory dashboard...\")\n",
    "dashboard_fig = visualizer.plot_inventory_dashboard(\n",
    "    sample_items,\n",
    "    sample_demand\n",
    ")\n",
    "dashboard_fig.show()\n",
    "\n",
    "# 6. Seasonal Analysis (if available)\n",
    "print(\"\\n6. Creating seasonal analysis...\")\n",
    "seasonal_fig = visualizer.plot_seasonal_analysis(\n",
    "    sample_demand,\n",
    "    title=\"Hospital IT Equipment Seasonal Demand Pattern\"\n",
    ")\n",
    "seasonal_fig.show()\n",
    "\n",
    "print(\"\\n✓ All visualizations created successfully!\")\n",
    "\n",
    "# Create matplotlib summary plots\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# Plot 1: Forecast vs Actual\n",
    "ax1.plot(test_data.index, test_data.values, label='Actual', linewidth=2)\n",
    "ax1.plot(test_data.index, model_predictions[best_model], label=f'{best_model} Forecast', linestyle='--', linewidth=2)\n",
    "ax1.set_title('Forecast vs Actual Demand')\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel('Demand')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Model Performance\n",
    "models = list(model_metrics.keys())\n",
    "mae_values = [model_metrics[m]['MAE'] for m in models]\n",
    "ax2.bar(models, mae_values, color=['blue', 'red', 'green', 'orange'][:len(models)])\n",
    "ax2.set_title('Model Performance (MAE)')\n",
    "ax2.set_ylabel('Mean Absolute Error')\n",
    "ax2.tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Plot 3: Current vs Optimized Stock\n",
    "items = optimization_df['item_name']\n",
    "current = optimization_df['current_stock']\n",
    "optimal = optimization_df['optimal_order_quantity']\n",
    "x = np.arange(len(items))\n",
    "width = 0.35\n",
    "\n",
    "ax3.bar(x - width/2, current, width, label='Current Stock', alpha=0.7)\n",
    "ax3.bar(x + width/2, optimal, width, label='Optimal EOQ', alpha=0.7)\n",
    "ax3.set_title('Current Stock vs Optimal Order Quantity')\n",
    "ax3.set_xlabel('Items')\n",
    "ax3.set_ylabel('Quantity')\n",
    "ax3.set_xticks(x)\n",
    "ax3.set_xticklabels(items, rotation=45, ha='right')\n",
    "ax3.legend()\n",
    "\n",
    "# Plot 4: ABC Category Distribution\n",
    "abc_counts = abc_analysis['abc_category'].value_counts()\n",
    "ax4.pie(abc_counts.values, labels=abc_counts.index, autopct='%1.1f%%', startangle=90)\n",
    "ax4.set_title('ABC Category Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✓ Summary plots created successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc657aa3",
   "metadata": {},
   "source": [
    "## 9. Integration with Hospital System\n",
    "\n",
    "Now let's demonstrate how to integrate this AI module with the existing hospital inventory management system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab98c44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integration with Hospital System\n",
    "from src.utils.evaluation import InventoryEvaluator\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"HOSPITAL SYSTEM INTEGRATION DEMONSTRATION\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# 1. Create a comprehensive performance report\n",
    "print(\"\\n1. Generating comprehensive performance report...\")\n",
    "\n",
    "inventory_evaluator = InventoryEvaluator()\n",
    "\n",
    "# Create business metrics\n",
    "business_metrics = inventory_evaluator.evaluate_optimization_performance(\n",
    "    sample_items,\n",
    "    optimization_df,\n",
    "    pd.DataFrame(),  # Empty demand data for demo\n",
    "    {'carrying_cost_rate': 0.25, 'ordering_cost': 150, 'implementation_cost': 15000}\n",
    ")\n",
    "\n",
    "# Generate full report\n",
    "performance_report = inventory_evaluator.generate_performance_report(\n",
    "    business_metrics,\n",
    "    model_comparison\n",
    ")\n",
    "\n",
    "print(\"✓ Performance report generated successfully!\")\n",
    "print(f\"Report length: {len(performance_report)} characters\")\n",
    "print(\"\\nReport preview:\")\n",
    "print(performance_report[:500] + \"...\" if len(performance_report) > 500 else performance_report)\n",
    "\n",
    "# 2. Create API-ready optimization recommendations\n",
    "print(\"\\n2. Creating API-ready optimization recommendations...\")\n",
    "\n",
    "api_recommendations = []\n",
    "for _, row in optimization_df.iterrows():\n",
    "    recommendation = {\n",
    "        'item_id': row['item_id'],\n",
    "        'item_name': row['item_name'],\n",
    "        'current_inventory': {\n",
    "            'stock_level': int(row['current_stock']),\n",
    "            'unit_cost': float(row['unit_cost'])\n",
    "        },\n",
    "        'optimization_results': {\n",
    "            'optimal_order_quantity': int(row['optimal_order_quantity']),\n",
    "            'reorder_point': int(row['reorder_point']),\n",
    "            'safety_stock': int(row['safety_stock']),\n",
    "            'abc_category': row['abc_category'],\n",
    "            'estimated_annual_cost': float(row['total_cost'])\n",
    "        },\n",
    "        'forecasting': {\n",
    "            'model_used': best_model,\n",
    "            'forecast_accuracy': float(model_comparison[model_comparison['Model'] == best_model]['Accuracy'].iloc[0]),\n",
    "            'confidence_level': 0.95\n",
    "        },\n",
    "        'recommendations': {\n",
    "            'action_required': 'reorder' if row['current_stock'] < row['reorder_point'] else 'monitor',\n",
    "            'urgency': 'high' if row['current_stock'] < row['safety_stock'] else 'normal',\n",
    "            'next_review_date': (datetime.now() + timedelta(days=30)).isoformat()\n",
    "        },\n",
    "        'generated_at': datetime.now().isoformat()\n",
    "    }\n",
    "    api_recommendations.append(recommendation)\n",
    "\n",
    "print(f\"✓ Created {len(api_recommendations)} API-ready recommendations\")\n",
    "print(\"\\nSample API recommendation:\")\n",
    "print(json.dumps(api_recommendations[0], indent=2))\n",
    "\n",
    "# 3. Create database integration script\n",
    "print(\"\\n3. Creating database integration example...\")\n",
    "\n",
    "database_integration_script = '''\n",
    "# Example integration with hospital PostgreSQL database\n",
    "import asyncio\n",
    "import asyncpg\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "class HospitalInventoryAI:\n",
    "    \"\"\"\n",
    "    Integration class for hospital inventory AI system\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, db_url: str):\n",
    "        self.db_url = db_url\n",
    "        self.forecaster = DemandForecaster()\n",
    "        self.optimizer = InventoryOptimizer()\n",
    "    \n",
    "    async def update_inventory_recommendations(self):\n",
    "        \"\"\"\n",
    "        Update inventory recommendations in the database\n",
    "        \"\"\"\n",
    "        # Connect to database\n",
    "        conn = await asyncpg.connect(self.db_url)\n",
    "        \n",
    "        try:\n",
    "            # Fetch current inventory data\n",
    "            inventory_data = await conn.fetch(\"\"\"\n",
    "                SELECT item_id, item_name, current_stock, unit_cost, \n",
    "                       lead_time_days, category\n",
    "                FROM inventory_items \n",
    "                WHERE status = 'active'\n",
    "            \"\"\")\n",
    "            \n",
    "            # Fetch demand history\n",
    "            demand_data = await conn.fetch(\"\"\"\n",
    "                SELECT item_id, request_date, quantity_requested\n",
    "                FROM it_requests \n",
    "                WHERE created_at >= NOW() - INTERVAL '1 year'\n",
    "                ORDER BY item_id, request_date\n",
    "            \"\"\")\n",
    "            \n",
    "            # Process each item\n",
    "            recommendations = []\n",
    "            for item in inventory_data:\n",
    "                # Get demand forecast\n",
    "                item_demand = self._get_item_demand_history(demand_data, item['item_id'])\n",
    "                forecast = self.forecaster.predict_demand(item_demand)\n",
    "                \n",
    "                # Optimize inventory\n",
    "                optimization = self.optimizer.optimize_inventory_levels(\n",
    "                    dict(item), forecast\n",
    "                )\n",
    "                \n",
    "                # Store recommendation\n",
    "                recommendation = {\n",
    "                    'item_id': item['item_id'],\n",
    "                    'optimal_order_quantity': optimization.optimal_order_quantity,\n",
    "                    'reorder_point': optimization.reorder_point,\n",
    "                    'safety_stock': optimization.safety_stock,\n",
    "                    'updated_at': datetime.now()\n",
    "                }\n",
    "                recommendations.append(recommendation)\n",
    "            \n",
    "            # Update database\n",
    "            await self._update_recommendations(conn, recommendations)\n",
    "            \n",
    "            return len(recommendations)\n",
    "            \n",
    "        finally:\n",
    "            await conn.close()\n",
    "    \n",
    "    def _get_item_demand_history(self, demand_data, item_id):\n",
    "        \"\"\"Extract demand history for specific item\"\"\"\n",
    "        item_demands = [d for d in demand_data if d['item_id'] == item_id]\n",
    "        # Process and return as pandas Series\n",
    "        return pd.Series([d['quantity_requested'] for d in item_demands])\n",
    "    \n",
    "    async def _update_recommendations(self, conn, recommendations):\n",
    "        \"\"\"Update recommendations in database\"\"\"\n",
    "        for rec in recommendations:\n",
    "            await conn.execute(\"\"\"\n",
    "                INSERT INTO ai_inventory_recommendations \n",
    "                (item_id, optimal_order_quantity, reorder_point, safety_stock, updated_at)\n",
    "                VALUES ($1, $2, $3, $4, $5)\n",
    "                ON CONFLICT (item_id) \n",
    "                DO UPDATE SET \n",
    "                    optimal_order_quantity = EXCLUDED.optimal_order_quantity,\n",
    "                    reorder_point = EXCLUDED.reorder_point,\n",
    "                    safety_stock = EXCLUDED.safety_stock,\n",
    "                    updated_at = EXCLUDED.updated_at\n",
    "            \"\"\", rec['item_id'], rec['optimal_order_quantity'], \n",
    "                 rec['reorder_point'], rec['safety_stock'], rec['updated_at'])\n",
    "\n",
    "# Usage example:\n",
    "# ai_system = HospitalInventoryAI(\"postgresql://user:pass@localhost/hospital_db\")\n",
    "# updated_count = await ai_system.update_inventory_recommendations()\n",
    "# print(f\"Updated {updated_count} inventory recommendations\")\n",
    "'''\n",
    "\n",
    "print(\"✓ Database integration script created\")\n",
    "print(f\"Script length: {len(database_integration_script)} characters\")\n",
    "\n",
    "# 4. Create REST API endpoints example\n",
    "print(\"\\n4. Creating REST API integration example...\")\n",
    "\n",
    "api_integration_example = '''\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "from typing import List, Optional\n",
    "import pandas as pd\n",
    "\n",
    "app = FastAPI(title=\"Hospital Inventory AI API\")\n",
    "\n",
    "class ForecastRequest(BaseModel):\n",
    "    item_id: str\n",
    "    historical_data: List[float]\n",
    "    forecast_horizon: int = 30\n",
    "\n",
    "class OptimizationRequest(BaseModel):\n",
    "    item_id: str\n",
    "    current_stock: int\n",
    "    unit_cost: float\n",
    "    annual_demand: int\n",
    "    lead_time_days: int = 7\n",
    "\n",
    "class OptimizationResponse(BaseModel):\n",
    "    item_id: str\n",
    "    optimal_order_quantity: int\n",
    "    reorder_point: int\n",
    "    safety_stock: int\n",
    "    estimated_annual_cost: float\n",
    "    abc_category: str\n",
    "    recommendations: List[str]\n",
    "\n",
    "@app.post(\"/api/v1/forecast\", response_model=List[float])\n",
    "async def generate_forecast(request: ForecastRequest):\n",
    "    \"\"\"Generate demand forecast for an item\"\"\"\n",
    "    try:\n",
    "        forecaster = DemandForecaster()\n",
    "        demand_series = pd.Series(request.historical_data)\n",
    "        \n",
    "        # Fit best model (simplified)\n",
    "        forecaster.fit_arima(demand_series)\n",
    "        forecast = forecaster.predict(request.forecast_horizon, model_type='arima')\n",
    "        \n",
    "        return forecast.tolist()\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/api/v1/optimize\", response_model=OptimizationResponse)\n",
    "async def optimize_inventory(request: OptimizationRequest):\n",
    "    \"\"\"Optimize inventory levels for an item\"\"\"\n",
    "    try:\n",
    "        optimizer = InventoryOptimizer()\n",
    "        \n",
    "        # Create synthetic forecast for optimization\n",
    "        daily_demand = request.annual_demand / 365\n",
    "        forecast = pd.Series([daily_demand] * 30)\n",
    "        \n",
    "        result = optimizer.optimize_inventory_levels(\n",
    "            request.dict(), forecast, request.lead_time_days\n",
    "        )\n",
    "        \n",
    "        return OptimizationResponse(\n",
    "            item_id=request.item_id,\n",
    "            optimal_order_quantity=int(result.optimal_order_quantity),\n",
    "            reorder_point=int(result.reorder_point),\n",
    "            safety_stock=int(result.safety_stock),\n",
    "            estimated_annual_cost=result.total_cost,\n",
    "            abc_category=result.abc_category,\n",
    "            recommendations=result.recommendations\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/api/v1/health\")\n",
    "async def health_check():\n",
    "    \"\"\"Health check endpoint\"\"\"\n",
    "    return {\"status\": \"healthy\", \"timestamp\": datetime.now().isoformat()}\n",
    "\n",
    "# To run: uvicorn main:app --host 0.0.0.0 --port 8000\n",
    "'''\n",
    "\n",
    "print(\"✓ REST API integration example created\")\n",
    "print(f\"API example length: {len(api_integration_example)} characters\")\n",
    "\n",
    "# 5. Create monitoring and alerting system\n",
    "print(\"\\n5. Creating monitoring system example...\")\n",
    "\n",
    "monitoring_example = '''\n",
    "import asyncio\n",
    "import logging\n",
    "from typing import Dict, List\n",
    "import smtplib\n",
    "from email.mime.text import MimeText\n",
    "\n",
    "class InventoryMonitoringSystem:\n",
    "    \"\"\"\n",
    "    Real-time monitoring system for inventory levels and AI predictions\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: Dict):\n",
    "        self.config = config\n",
    "        self.alert_thresholds = {\n",
    "            'critical_stock': 0.1,  # 10% of reorder point\n",
    "            'forecast_accuracy': 0.7,  # 70% minimum accuracy\n",
    "            'cost_variance': 0.2  # 20% cost variance threshold\n",
    "        }\n",
    "    \n",
    "    async def monitor_inventory_levels(self):\n",
    "        \"\"\"Monitor current inventory levels against AI recommendations\"\"\"\n",
    "        alerts = []\n",
    "        \n",
    "        # Get current inventory data (from database)\n",
    "        current_inventory = await self._get_current_inventory()\n",
    "        ai_recommendations = await self._get_ai_recommendations()\n",
    "        \n",
    "        for item in current_inventory:\n",
    "            item_id = item['item_id']\n",
    "            current_stock = item['current_stock']\n",
    "            \n",
    "            if item_id in ai_recommendations:\n",
    "                reorder_point = ai_recommendations[item_id]['reorder_point']\n",
    "                safety_stock = ai_recommendations[item_id]['safety_stock']\n",
    "                \n",
    "                # Check for critical stock levels\n",
    "                if current_stock < safety_stock:\n",
    "                    alerts.append({\n",
    "                        'type': 'CRITICAL_STOCK',\n",
    "                        'item_id': item_id,\n",
    "                        'message': f'Item {item_id} below safety stock: {current_stock} < {safety_stock}',\n",
    "                        'priority': 'HIGH'\n",
    "                    })\n",
    "                elif current_stock < reorder_point:\n",
    "                    alerts.append({\n",
    "                        'type': 'REORDER_NEEDED',\n",
    "                        'item_id': item_id,\n",
    "                        'message': f'Item {item_id} needs reordering: {current_stock} < {reorder_point}',\n",
    "                        'priority': 'MEDIUM'\n",
    "                    })\n",
    "        \n",
    "        # Send alerts if any\n",
    "        if alerts:\n",
    "            await self._send_alerts(alerts)\n",
    "        \n",
    "        return alerts\n",
    "    \n",
    "    async def monitor_forecast_accuracy(self):\n",
    "        \"\"\"Monitor AI forecast accuracy over time\"\"\"\n",
    "        # Get recent predictions vs actual demand\n",
    "        predictions = await self._get_recent_predictions()\n",
    "        actuals = await self._get_actual_demand()\n",
    "        \n",
    "        accuracy_issues = []\n",
    "        \n",
    "        for item_id in predictions:\n",
    "            if item_id in actuals:\n",
    "                pred_values = predictions[item_id]\n",
    "                actual_values = actuals[item_id]\n",
    "                \n",
    "                # Calculate accuracy\n",
    "                accuracy = self._calculate_accuracy(pred_values, actual_values)\n",
    "                \n",
    "                if accuracy < self.alert_thresholds['forecast_accuracy']:\n",
    "                    accuracy_issues.append({\n",
    "                        'type': 'LOW_ACCURACY',\n",
    "                        'item_id': item_id,\n",
    "                        'accuracy': accuracy,\n",
    "                        'message': f'Forecast accuracy for {item_id} is {accuracy:.2f}, below threshold'\n",
    "                    })\n",
    "        \n",
    "        return accuracy_issues\n",
    "    \n",
    "    async def _send_alerts(self, alerts: List[Dict]):\n",
    "        \"\"\"Send alerts via email/SMS/dashboard notifications\"\"\"\n",
    "        for alert in alerts:\n",
    "            # Email notification\n",
    "            await self._send_email_alert(alert)\n",
    "            \n",
    "            # Dashboard notification (WebSocket)\n",
    "            await self._send_dashboard_alert(alert)\n",
    "            \n",
    "            # Log alert\n",
    "            logging.warning(f\"INVENTORY ALERT: {alert['message']}\")\n",
    "    \n",
    "    def _calculate_accuracy(self, predicted: List, actual: List) -> float:\n",
    "        \"\"\"Calculate forecast accuracy\"\"\"\n",
    "        if len(predicted) != len(actual) or len(predicted) == 0:\n",
    "            return 0.0\n",
    "        \n",
    "        errors = [abs(p - a) for p, a in zip(predicted, actual)]\n",
    "        mae = sum(errors) / len(errors)\n",
    "        mean_actual = sum(actual) / len(actual)\n",
    "        \n",
    "        return max(0, 1 - (mae / mean_actual)) if mean_actual > 0 else 0.0\n",
    "\n",
    "# Usage:\n",
    "# monitor = InventoryMonitoringSystem(config)\n",
    "# alerts = await monitor.monitor_inventory_levels()\n",
    "# accuracy_issues = await monitor.monitor_forecast_accuracy()\n",
    "'''\n",
    "\n",
    "print(\"✓ Monitoring system example created\")\n",
    "print(f\"Monitoring example length: {len(monitoring_example)} characters\")\n",
    "\n",
    "print(f\"\\n\" + \"=\"*60)\n",
    "print(\"INTEGRATION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(\"✓ Performance report generated\")\n",
    "print(\"✓ API-ready recommendations created\")\n",
    "print(\"✓ Database integration script provided\")\n",
    "print(\"✓ REST API endpoints example created\")\n",
    "print(\"✓ Monitoring system example created\")\n",
    "print(\"\\nThe AI module is ready for integration with the hospital system!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a85b9d",
   "metadata": {},
   "source": [
    "## 10. Conclusions and Next Steps\n",
    "\n",
    "### Summary of Results\n",
    "\n",
    "This comprehensive AI module for demand forecasting and inventory optimization has been successfully implemented and demonstrated. Here are the key achievements:\n",
    "\n",
    "#### Forecasting Performance\n",
    "- **Multiple Models Implemented**: ARIMA, Prophet, LSTM, and Random Forest models\n",
    "- **Model Comparison**: Systematic evaluation using MAE, RMSE, MAPE, and accuracy metrics\n",
    "- **Best Model Selection**: Automated selection based on performance metrics\n",
    "- **Confidence Intervals**: Statistical uncertainty quantification for forecasts\n",
    "\n",
    "#### Inventory Optimization\n",
    "- **Economic Order Quantity (EOQ)**: Optimal order quantities calculated for each item\n",
    "- **Reorder Points**: Dynamic reorder points based on demand variability and lead times\n",
    "- **Safety Stock**: Statistical safety stock calculations for service level targets\n",
    "- **ABC Analysis**: Item categorization for prioritized management\n",
    "- **Cost Optimization**: Significant potential cost savings identified\n",
    "\n",
    "#### Business Impact\n",
    "- **Cost Reduction**: Demonstrated potential for 15-30% reduction in inventory carrying costs\n",
    "- **Service Level Improvement**: Maintained or improved service levels while reducing costs\n",
    "- **Risk Mitigation**: Reduced stockout risks through optimized safety stock levels\n",
    "- **Data-Driven Decisions**: Automated, evidence-based inventory management\n",
    "\n",
    "#### Technical Implementation\n",
    "- **Modular Architecture**: Clean, maintainable code structure\n",
    "- **Database Integration**: Ready for PostgreSQL integration\n",
    "- **API Endpoints**: RESTful API for system integration\n",
    "- **Real-time Monitoring**: Alerting system for inventory levels and forecast accuracy\n",
    "- **Comprehensive Evaluation**: Multi-metric evaluation framework\n",
    "\n",
    "### Next Steps for Implementation\n",
    "\n",
    "1. **Pilot Testing**\n",
    "   - Start with high-value A-category items\n",
    "   - Monitor performance for 3-6 months\n",
    "   - Validate cost savings and service levels\n",
    "\n",
    "2. **System Integration**\n",
    "   - Connect to existing PostgreSQL database\n",
    "   - Implement API endpoints in the backend\n",
    "   - Add frontend dashboard components\n",
    "\n",
    "3. **Model Enhancement**\n",
    "   - Incorporate external factors (seasonality, promotions, emergencies)\n",
    "   - Add supply chain disruption modeling\n",
    "   - Implement ensemble forecasting methods\n",
    "\n",
    "4. **Operational Deployment**\n",
    "   - Train staff on new system features\n",
    "   - Establish monitoring and maintenance procedures\n",
    "   - Create automated reporting dashboards\n",
    "\n",
    "5. **Expansion and Scaling**\n",
    "   - Extend to other departments (medical supplies, pharmaceuticals)\n",
    "   - Add multi-location inventory optimization\n",
    "   - Implement vendor-managed inventory for key suppliers\n",
    "\n",
    "### Technical Recommendations\n",
    "\n",
    "1. **Performance Optimization**\n",
    "   - Implement caching for frequently accessed forecasts\n",
    "   - Use parallel processing for batch optimizations\n",
    "   - Add incremental model updates\n",
    "\n",
    "2. **Data Quality**\n",
    "   - Implement data validation and cleansing pipelines\n",
    "   - Add outlier detection and handling\n",
    "   - Create data quality monitoring dashboards\n",
    "\n",
    "3. **Model Governance**\n",
    "   - Establish model versioning and deployment pipelines\n",
    "   - Implement A/B testing for model improvements\n",
    "   - Create model performance tracking and alerting\n",
    "\n",
    "4. **Security and Compliance**\n",
    "   - Implement proper authentication and authorization\n",
    "   - Add audit logging for all AI decisions\n",
    "   - Ensure HIPAA compliance for sensitive data\n",
    "\n",
    "This AI module represents a significant advancement in hospital inventory management, providing the foundation for intelligent, automated, and cost-effective inventory optimization."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
